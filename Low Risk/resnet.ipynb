{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57318b-fd3d-439f-8798-f88dcd71069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTS\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import dill\n",
    "from e2cnn import gspaces\n",
    "# from e2cnn import nn\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48389568-947f-4a14-84f0-d7eaee759ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_dict = {}\n",
    "\n",
    "for plant_disease in os.listdir('Dataset/Dataset/'):\n",
    "    disease_dict[plant_disease] = len(os.listdir('Dataset/Dataset/' + plant_disease))\n",
    "\n",
    "disease_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9cb6a-fef7-421e-85e9-180315df94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path, batch_size):\n",
    "    \n",
    "    transform = transforms.Compose(\n",
    "        [transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor()]\n",
    "    )\n",
    "    \n",
    "    dataset = datasets.ImageFolder(path, transform = transform)\n",
    "    \n",
    "    indices = list(range(len(dataset)))\n",
    "    \n",
    "    split = int(np.floor(0.85 * len(dataset)))\n",
    "    \n",
    "    validation = int(np.floor(0.70 * split))\n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_indices, validation_indices, test_indices = (\n",
    "        indices[:validation//16],\n",
    "        indices[validation//16:split//16],\n",
    "        indices[split//16:((split//16)+100)]\n",
    "    )\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=test_sampler\n",
    "    )\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=validation_sampler\n",
    "    )    \n",
    "    \n",
    "    return dataset, train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ab8ad2-321c-42f6-9309-c3dec65cddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, train_loader, validation_loader, test_loader = data_loader(path = 'Dataset/Dataset/', batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5e3c7-2c7f-49a0-bda6-0948ea3fca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RpsClassifier, self).__init__()\n",
    "        self.block1 = self.conv_block(c_in=3, c_out=256, dropout=0.1, kernel_size=5, stride=1, padding=2)\n",
    "        self.block2 = self.conv_block(c_in=256, c_out=128, dropout=0.1, kernel_size=3, stride=1, padding=1)\n",
    "        self.block3 = self.conv_block(c_in=128, c_out=64, dropout=0.1, kernel_size=3, stride=1, padding=1)\n",
    "        self.lastcnn = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=75, stride=1, padding=0)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.lastcnn(x)\n",
    "        return x\n",
    "    \n",
    "    def conv_block(self, c_in, c_out, dropout, **kwargs):\n",
    "        seq_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c_in, out_channels=c_out, **kwargs),\n",
    "            nn.BatchNorm2d(num_features=c_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=dropout)\n",
    "        )\n",
    "        return seq_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2d4a2-09b0-4ed8-a1e7-8bb185f713fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "model = ResNet()\n",
    "model.to(device)\n",
    "# print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a7c44-2747-4bf4-95a5-359a8c2cff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00dcf2-b029-4fe2-aa9b-1873247722a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c43c2b-7a4b-483a-9c6f-354d503a8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in tqdm(range(n_epochs = 10)):\n",
    "    \n",
    "    # Train\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    model.train()\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_train_pred = model(X_train_batch).squeeze()\n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            y_val_pred = model(X_val_batch).squeeze()\n",
    "            y_val_pred = torch.unsqueeze(y_val_pred, 0)\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "            val_epoch_loss += train_loss.item()\n",
    "            val_epoch_acc += train_acc.item()\n",
    "            \n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "    print(f'Epoch {e+0:02}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bed5629-3154-409c-8e4c-3b7c1227c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTS\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import dill\n",
    "from e2cnn import gspaces\n",
    "# from e2cnn import nn\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39e3474-47b0-47f0-9648-6f46b062c6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple___Apple_scab': 1000,\n",
       " 'Apple___Black_rot': 1000,\n",
       " 'Apple___Cedar_apple_rust': 1000,\n",
       " 'Apple___healthy': 1645,\n",
       " 'Background_without_leaves': 1143,\n",
       " 'Blueberry___healthy': 1502,\n",
       " 'Cherry___healthy': 1000,\n",
       " 'Cherry___Powdery_mildew': 1052,\n",
       " 'Corn___Cercospora_leaf_spot Gray_leaf_spot': 1000,\n",
       " 'Corn___Common_rust': 1192,\n",
       " 'Corn___healthy': 1162,\n",
       " 'Corn___Northern_Leaf_Blight': 1000,\n",
       " 'Grape___Black_rot': 1180,\n",
       " 'Grape___Esca_(Black_Measles)': 1383,\n",
       " 'Grape___healthy': 1000,\n",
       " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 1076,\n",
       " 'Orange___Haunglongbing_(Citrus_greening)': 5507,\n",
       " 'Peach___Bacterial_spot': 2297,\n",
       " 'Peach___healthy': 1000,\n",
       " 'Pepper,_bell___Bacterial_spot': 1000,\n",
       " 'Pepper,_bell___healthy': 1478,\n",
       " 'Potato___Early_blight': 1000,\n",
       " 'Potato___healthy': 1000,\n",
       " 'Potato___Late_blight': 1000,\n",
       " 'Raspberry___healthy': 1000,\n",
       " 'Soybean___healthy': 5090,\n",
       " 'Squash___Powdery_mildew': 1835,\n",
       " 'Strawberry___healthy': 1000,\n",
       " 'Strawberry___Leaf_scorch': 1109,\n",
       " 'Tomato___Bacterial_spot': 2127,\n",
       " 'Tomato___Early_blight': 1000,\n",
       " 'Tomato___healthy': 1591,\n",
       " 'Tomato___Late_blight': 1909,\n",
       " 'Tomato___Leaf_Mold': 1000,\n",
       " 'Tomato___Septoria_leaf_spot': 1771,\n",
       " 'Tomato___Spider_mites Two-spotted_spider_mite': 1676,\n",
       " 'Tomato___Target_Spot': 1404,\n",
       " 'Tomato___Tomato_mosaic_virus': 1000,\n",
       " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 5357}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_dict = {}\n",
    "\n",
    "for plant_disease in os.listdir('Dataset/Dataset/'):\n",
    "    disease_dict[plant_disease] = len(os.listdir('Dataset/Dataset/' + plant_disease))\n",
    "\n",
    "disease_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1503da-f645-460f-b787-103fb544f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path, batch_size):\n",
    "    \n",
    "    transform = transforms.Compose(\n",
    "        [transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor()]\n",
    "    )\n",
    "    \n",
    "    dataset = datasets.ImageFolder(path, transform = transform)\n",
    "    \n",
    "    indices = list(range(len(dataset)))\n",
    "    \n",
    "    split = int(np.floor(0.85 * len(dataset)))\n",
    "    \n",
    "    validation = int(np.floor(0.70 * split))\n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_indices, validation_indices, test_indices = (\n",
    "        indices[:validation//16],\n",
    "        indices[validation//16:split//16],\n",
    "        indices[split//16:((split//16)+100)]\n",
    "    )\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=test_sampler\n",
    "    )\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=validation_sampler\n",
    "    )    \n",
    "    \n",
    "    return dataset, train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d99348a-64ea-4b0a-8eec-b1ed3e5dbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, train_loader, validation_loader, test_loader = data_loader(path = 'Dataset/Dataset/', batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa503d-6234-4d79-a440-84afe555b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691b29b-c335-4920-9d14-50858f5d9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = len(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc84e80-59cc-4ef3-8499-141129536631",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a9bc3-cb14-4b60-9137-b61e14350dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, train_loader, validation_loader, test_laoder, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    validation_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(inputs)\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "            train_loss.append(loss.item())  # torch to numpy world\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        validation_loss = []\n",
    "\n",
    "        for inputs, targets in tqdm(validation_loader):\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "            validation_loss.append(loss.item())  # torch to numpy world\n",
    "\n",
    "        validation_loss = np.mean(validation_loss)\n",
    "\n",
    "        train_losses[e] = train_loss\n",
    "        validation_losses[e] = validation_loss\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "\n",
    "        print(\n",
    "            f\"Epoch : {e+1}/{epochs} Train_loss:{train_loss:.3f} Test_loss:{validation_loss:.3f} Duration:{dt}\"\n",
    "        )\n",
    "\n",
    "    return train_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d1f47-e734-4913-a6ed-e85353ce1158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c2a5b-5fd8-4c95-b6d1-e74753a55767",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7befb863-ec6d-4da6-8ee6-0375512e1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTS\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import dill\n",
    "from e2cnn import gspaces\n",
    "# from e2cnn import nn\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd1f6e-57a8-4b6e-93f5-2b90b3bfd1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_dict = {}\n",
    "\n",
    "for plant_disease in os.listdir('Dataset/Dataset/'):\n",
    "    disease_dict[plant_disease] = len(os.listdir('Dataset/Dataset/' + plant_disease))\n",
    "\n",
    "disease_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0121dd-858d-4960-b53b-f80d63da596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path, batch_size):\n",
    "    \n",
    "    transform = transforms.Compose(\n",
    "        [transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor()]\n",
    "    )\n",
    "    \n",
    "    dataset = datasets.ImageFolder(path, transform = transform)\n",
    "    \n",
    "    indices = list(range(len(dataset)))\n",
    "    \n",
    "    split = int(np.floor(0.85 * len(dataset)))\n",
    "    \n",
    "    validation = int(np.floor(0.70 * split))\n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_indices, validation_indices, test_indices = (\n",
    "        indices[:validation//16],\n",
    "        indices[validation//16:split//16],\n",
    "        indices[split//16:((split//16)+100)]\n",
    "    )\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=test_sampler\n",
    "    )\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=validation_sampler\n",
    "    )    \n",
    "    \n",
    "    return dataset, train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a943a3-f20e-4590-a64d-c969381d513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, train_loader, validation_loader, test_loader = data_loader(path = 'Dataset/Dataset/', batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5ab66-0b43-4bac-aad8-c66fb505457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Rotational Equivariant Unet '''\n",
    "\n",
    "class rot_conv2d(torch.nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size, stride, N, activation = True, deconv = False, last_deconv = False):\n",
    "        super(rot_conv2d, self).__init__()       \n",
    "        r2_act = gspaces.Rot2dOnR2(N = N)\n",
    "        \n",
    "        feat_type_in = nn.FieldType(r2_act, input_channels*[r2_act.regular_repr])\n",
    "        feat_type_hid = nn.FieldType(r2_act, output_channels*[r2_act.regular_repr])\n",
    "        if not deconv:\n",
    "            if activation:\n",
    "                self.layer = nn.SequentialModule(\n",
    "                    nn.R2Conv(feat_type_in, feat_type_hid, kernel_size = kernel_size, stride = stride, padding = (kernel_size - 1)//2),\n",
    "                    nn.InnerBatchNorm(feat_type_hid),\n",
    "                    nn.ReLU(feat_type_hid)\n",
    "                ) \n",
    "            else:\n",
    "                self.layer = nn.R2Conv(feat_type_in, feat_type_hid, kernel_size = kernel_size, stride = stride,padding = (kernel_size - 1)//2)\n",
    "        else:\n",
    "            if last_deconv:\n",
    "                feat_type_in = nn.FieldType(r2_act, input_channels*[r2_act.regular_repr])\n",
    "                feat_type_hid = nn.FieldType(r2_act, output_channels*[r2_act.irrep(0)])\n",
    "                self.layer = nn.R2Conv(feat_type_in, feat_type_hid, kernel_size = kernel_size, stride = stride, padding = 0)\n",
    "            else:\n",
    "                self.layer = nn.SequentialModule(\n",
    "                        nn.R2Conv(feat_type_in, feat_type_hid, kernel_size = kernel_size, stride = stride, padding = 0),\n",
    "                        nn.InnerBatchNorm(feat_type_hid),\n",
    "                        nn.ReLU(feat_type_hid)\n",
    "                    ) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "class rot_deconv2d(torch.nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, N, last_deconv = False):\n",
    "        super(rot_deconv2d, self).__init__()\n",
    "        self.conv2d = rot_conv2d(input_channels = input_channels, output_channels = output_channels, kernel_size = 4, \n",
    "                             activation = True, stride = 1, N = N, deconv = True, last_deconv = last_deconv)\n",
    "        r2_act = gspaces.Rot2dOnR2(N = N)\n",
    "        self.feat_type = nn.FieldType(r2_act, input_channels*[r2_act.regular_repr])\n",
    "        \n",
    "    def pad(self, x):\n",
    "        new_x = torch.zeros(x.shape[0], x.shape[1], x.shape[2]*2 + 3, x.shape[3]*2 + 3)\n",
    "        new_x[:,:,:-3,:-3][:,:,::2,::2] = x\n",
    "        new_x[:,:,:-3,:-3][:,:,1::2,1::2] = x\n",
    "        new_x = nn.GeometricTensor(new_x, self.feat_type)\n",
    "        return new_x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.pad(x).to(device)\n",
    "        return self.conv2d(out)\n",
    "    \n",
    "class Unet_Rot(torch.nn.Module):\n",
    "    def __init__(self, input_frames, output_frames, kernel_size, N):\n",
    "        super(Unet_Rot, self).__init__()\n",
    "        r2_act = gspaces.Rot2dOnR2(N = N)\n",
    "        self.feat_type_in = nn.FieldType(r2_act, input_frames*[r2_act.irrep(0)])\n",
    "        self.feat_type_in_hid = nn.FieldType(r2_act, 32*[r2_act.regular_repr])\n",
    "        self.feat_type_hid_out = nn.FieldType(r2_act, (16 + input_frames)*[r2_act.irrep(0)])\n",
    "        self.feat_type_out = nn.FieldType(r2_act, output_frames*[r2_act.irrep(0)])\n",
    "        \n",
    "        self.conv1 = nn.SequentialModule(\n",
    "            nn.R2Conv(self.feat_type_in, self.feat_type_in_hid, kernel_size = kernel_size, stride = 2, padding = (kernel_size - 1)//2),\n",
    "            nn.InnerBatchNorm(self.feat_type_in_hid),\n",
    "            nn.ReLU(self.feat_type_in_hid)\n",
    "        )\n",
    "\n",
    "        self.conv2 = rot_conv2d(32, 64, kernel_size = kernel_size, stride = 1, N = N)\n",
    "        self.conv2_1 = rot_conv2d(64, 64, kernel_size = kernel_size, stride = 1, N = N)\n",
    "        self.conv3 = rot_conv2d(64, 128, kernel_size = kernel_size, stride = 2, N = N)\n",
    "        self.conv3_1 = rot_conv2d(128, 128, kernel_size = kernel_size, stride = 1, N = N)\n",
    "        self.conv4 = rot_conv2d(128, 256, kernel_size = kernel_size, stride = 2, N = N)\n",
    "        self.conv4_1 = rot_conv2d(256, 256, kernel_size = kernel_size, stride = 1, N = N)\n",
    "\n",
    "        self.deconv3 = rot_deconv2d(256, 64, N)\n",
    "        self.deconv2 = rot_deconv2d(192, 32, N)\n",
    "        self.deconv1 = rot_deconv2d(96, 16, N, last_deconv = True)\n",
    "\n",
    "    \n",
    "        self.output_layer = nn.R2Conv(self.feat_type_hid_out, self.feat_type_out, kernel_size = kernel_size, padding = (kernel_size - 1)//2)\n",
    "      \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = nn.GeometricTensor(x, self.feat_type_in)\n",
    "        out_conv1 = self.conv1(x)\n",
    "        out_conv2 = self.conv2_1(self.conv2(out_conv1))\n",
    "        out_conv3 = self.conv3_1(self.conv3(out_conv2))\n",
    "        out_conv4 = self.conv4_1(self.conv4(out_conv3))\n",
    "\n",
    "        out_deconv3 = self.deconv3(out_conv4.tensor)\n",
    "        concat3 = torch.cat((out_conv3.tensor, out_deconv3.tensor), 1)\n",
    "        out_deconv2 = self.deconv2(concat3)\n",
    "        concat2 = torch.cat((out_conv2.tensor, out_deconv2.tensor), 1)\n",
    "        out_deconv1 = self.deconv1(concat2)\n",
    "\n",
    "        concat0 = torch.cat((x.tensor, out_deconv1.tensor), 1)\n",
    "        concat0 = nn.GeometricTensor(concat0, self.feat_type_hid_out)\n",
    "        out = self.output_layer(concat0)\n",
    "        return out.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf2606-56c6-4902-929d-257d4004a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Train epoch function '''\n",
    "\n",
    "def train_epoch(train_loader, model, optimizer, loss_function):\n",
    "    train_mse = []\n",
    "\n",
    "    for xx, yy in train_loader:\n",
    "        \n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "\n",
    "        # xx = xx.unsqueeze(1)\n",
    "        # yy = yy.unsqueeze(1)\n",
    "\n",
    "        loss = 0\n",
    "        ims = []\n",
    "\n",
    "        for y in yy.transpose(0, 1):\n",
    "            y = y.unsqueeze(1)\n",
    "            im = model(xx)\n",
    "            xx = torch.cat([xx[:, 2:], im], 1)\n",
    "            loss += loss_function(im, y)\n",
    "        \n",
    "        train_mse.append(loss.item()/yy.shape[1]) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_mse = round(np.sqrt(np.mean(train_mse)),5)\n",
    "    return train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936cace-268f-484a-becd-4ddc34326d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Eval epoch function '''\n",
    "\n",
    "def eval_epoch(valid_loader, model, loss_function):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for xx, yy in valid_loader:\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            # xx = xx.unsqueeze(1)\n",
    "            # yy = yy.unsqueeze(1)\n",
    "\n",
    "            loss = 0\n",
    "            ims = []\n",
    "            for y in yy.transpose(0, 1):\n",
    "                y = y.unsqueeze(1)\n",
    "                im = model(xx)\n",
    "                xx = torch.cat([xx[:, 2:], im], 1)\n",
    "                loss += loss_function(im, y)\n",
    "                ims.append(im.unsqueeze(1).cpu().data.numpy())\n",
    "                \n",
    "            ims = np.concatenate(ims, axis = 1)\n",
    "            preds.append(ims)\n",
    "            trues.append(yy.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item()/yy.shape[1])\n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = round(np.sqrt(np.mean(valid_mse)), 5)\n",
    "    return valid_mse, preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634123b-2992-4d2b-accc-1f111f6d58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Test epoch function '''\n",
    "\n",
    "def test_epoch(valid_loader, model, loss_function):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        loss_curve = []\n",
    "        for xx, yy in valid_loader:\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            # xx = xx.unsqueeze(1)\n",
    "            # yy = yy.unsqueeze(1)\n",
    "\n",
    "            loss = 0\n",
    "            ims = []\n",
    "            \n",
    "            for y in yy.transpose(0, 1):\n",
    "                y = y.unsqueeze(1)\n",
    "                im = model(xx)\n",
    "                xx = torch.cat([xx[:, 2:], im], 1)\n",
    "                mse = loss_function(im, y)\n",
    "                loss += mse\n",
    "                loss_curve.append(mse.item())\n",
    "                ims.append(im.unsqueeze(1).cpu().data.numpy())\n",
    "           \n",
    "            ims = np.concatenate(ims, axis = 1)\n",
    "            preds.append(ims)\n",
    "            trues.append(yy.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item()/yy.shape[1])\n",
    "            \n",
    "        loss_curve = np.array(loss_curve).reshape(-1,yy.shape[1])\n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = np.mean(valid_mse)\n",
    "        loss_curve = np.sqrt(np.mean(loss_curve, axis = 0))\n",
    "    return valid_mse, preds, trues, loss_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc9c2f2-f91a-45b7-8cde-2013a7ca9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model Hyperparameters '''\n",
    "\n",
    "n_epochs = 1\n",
    "learning_rate = 0.001\n",
    "lr_decay = 0.9\n",
    "\n",
    "min_mse = 100\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "test_mse = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed87c2d-d9d6-44ce-93d6-0ff468653283",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model '''\n",
    "\n",
    "rot_unet_model = torch.nn.DataParallel(Unet_Rot(input_frames = 3, output_frames = 1, kernel_size = 3, N = 4).to(device))\n",
    "\n",
    "optimizer = torch.optim.Adam(rot_unet_model.parameters(), learning_rate,betas=(learning_rate, 0.999), weight_decay=4e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 1, gamma=lr_decay)\n",
    "loss_fun = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8323b63a-bdfb-4ff1-94cd-27c18bafe648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rot_unet_model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
